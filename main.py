from dotenv import load_dotenv
load_dotenv()

from langchain.retrievers.contextual_compression import ContextualCompressionRetriever
from langchain_cohere import CohereRerank

from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer
from langgraph.graph import END, StateGraph, START
from langchain_qdrant import FastEmbedSparse
from langchain.schema import Document
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI
from fastapi.middleware.cors import CORSMiddleware

from database import QdrantVT
from router import QueryRouter
from tools import ToolSearch
from database.chat_history import ChatHistoryManager

from typing_extensions import TypedDict
from typing import List

from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
from typing import Optional
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi import HTTPException, Request, Form

from pprint import pprint
from database.create_docs import extract_text_from_pdf, LawDocumentCreator
import os

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # Cho ph√©p origin c·ªßa giao di·ªán
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

### Kh·ªüi t·∫°o c√°c CONSTANT ###
#HUGGINGFACE_MODEL = "intfloat/multilingual-e5-base"
HUGGINGFACE_MODEL = 'keepitreal/vietnamese-sbert'
FAST_EMBED_SPARSE_MODEL = "Qdrant/bm42-all-minilm-l6-v2-attentions"
# LLM_MODEL = "llama-3.1-8b-instant"
LLM_MODEL = "sonar-pro"
COLLECTION_NAME = "law_collection"
VN_LAW_PDF_PATH = "VanBanGoc_52.2014.QH13.pdf"


### Kh·ªüi t·∫°o ChatHistoryManager ###
DB_CONFIG = {
    "host": os.getenv("DB_HOST", "localhost"),
    "user": os.getenv("DB_USER", "root"),
    "password": os.getenv("DB_PASSWORD", "hoangducdung"),
    "database": os.getenv("DB_NAME", "law_db")
}

chat_history_manager = ChatHistoryManager(**DB_CONFIG)

### Kh·ªüi t·∫°o c√°c ƒë·ªëi t∆∞·ª£ng ###
embeddings = HuggingFaceEmbeddings(model_name=HUGGINGFACE_MODEL)
sparse = FastEmbedSparse(model_name=FAST_EMBED_SPARSE_MODEL, batch_size=4)
collection = COLLECTION_NAME

###  ###
qdrant_vectors = QdrantVT(collectionName=collection, embeddingModel=embeddings, SparseModel=sparse)
# llm = ChatGroq(model_name=LLM_MODEL, api_key="")
llm = ChatOpenAI(
    api_key="",
    base_url="https://api.perplexity.ai",
    model_name = LLM_MODEL
)
query_router = QueryRouter(llm=llm)
tool = ToolSearch()
wiki_tool = tool.wiki
documents = qdrant_vectors.load_documents(pdf_path=VN_LAW_PDF_PATH)
try:
    qdrant_vectors.client.get_collection(collection) 
    retriever = qdrant_vectors.load_vectorstore()

    
except:
    retriever = qdrant_vectors.init_vectorstore()
    
compressor =  CohereRerank(cohere_api_key="", model="rerank-multilingual-v3.0")
rerank_retriever = ContextualCompressionRetriever(
    base_compressor=compressor, base_retriever=retriever
)

### FUNCTIONS ###
class GraphState(TypedDict):
    """
    TraÃ£ng thaÃÅi cuÃâa ƒë√¥ÃÄ thiÃ£

    Attributes:
        question: c√¢u h·ªèi
        session_id: ID c·ªßa session ƒë·ªÉ l·∫•y context
        instruction: h∆∞·ªõng d·∫´n ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        generation: LLM generation
        documents: danh s√°ch c√°c vƒÉn b·∫£n
        answer: c√¢u tr·∫£ l·ªùi
    """
    question: str
    session_id: str  # Th√™m field n√†y
    instruction: str
    generation: str
    documents: List[str]
    answer: str

def retrieve(state):
    print("---RETRIEVE---")
    instruction = state["instruction"]
    question = state["question"]    
    documents = rerank_retriever.invoke(instruction)
    print(f"Number of documents retrieved: {len(documents)}")
    
    text = ""
    
    for i, result in enumerate(documents):
        try:
            print(f"Document {i} metadata keys: {list(result.metadata.keys())}")
            print(f"Document {i} metadata: {result.metadata}")
            
            # Safely get metadata with default values using .get()
            chapter_number = result.metadata.get('chapter_number', 'N/A')
            chapter_title = result.metadata.get('chapter_title', 'N/A')
            article_number = result.metadata.get('article_number', 'N/A')
            
            print(f"Extracted - Chapter: {chapter_number}, Title: {chapter_title}, Article: {article_number}")
            
            # Format the text with safe metadata access
            if chapter_number != 'N/A' and chapter_title != 'N/A' and article_number != 'N/A':
                # Full metadata available
                text += f"{i+1}. {chapter_number} - {chapter_title} - {article_number}\n {result.page_content}\n\n"
            else:
                # Missing some metadata, use a simpler format
                text += f"{i+1}. {article_number if article_number != 'N/A' else 'ƒêi·ªÅu kh√¥ng x√°c ƒë·ªãnh'}\n {result.page_content}\n\n"
                
        except Exception as e:
            print(f"Error processing document {i}: {str(e)}")
            print(f"Document type: {type(result)}")
            print(f"Has metadata attr: {hasattr(result, 'metadata')}")
            if hasattr(result, 'metadata'):
                print(f"Metadata type: {type(result.metadata)}")
            # Fallback to simple format
            text += f"{i+1}. N·ªôi dung ph√°p l√Ω\n {result.page_content}\n\n"
    
    print("---RETRIEVE COMPLETED---")
    return {"documents": text, "question": question}

def wiki_search(state):

    print("---WIKI_SEARCH---")
    question = state["question"]
    wiki_results = wiki_tool.invoke({"query": question})
    wiki_results = Document(page_content=wiki_results)
    return {"documents": wiki_results, "question": question}

def route_question(state):
    
    print("---ROUTE_QUESTION---")
    question = state["question"]
    source = query_router.route_question(question)

    if source.datasource == "wiki_search":
        print("---ROUTE QUESTION TO WIKI SEARCH---")
        return "wiki_search"
    elif source.datasource == "vectorstore":
        print("---ROUTE QUESTION TO VECTORSTORE---")
        return "vectorstore"

def preprocess_query(state):
    # prompt = f"""
    # B·∫°n l√† chuy√™n gia Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh Vi·ªát Nam 2014. Khi nh·∫≠n ƒë∆∞·ª£c m·ªôt t√¨nh hu·ªëng ho·∫∑c c√¢u h·ªèi, h√£y:
    # 1.T√≥m t·∫Øt n·ªôi dung ch√≠nh c·ªßa t√¨nh hu·ªëng.
    # 2.Tr√≠ch xu·∫•t c√°c t·ª´ kh√≥a quan tr·ªçng.
    # 3.Li·ªát k√™ s·ªë ƒëi·ªÅu v√† t√™n ƒëi·ªÅu trong lu·∫≠t c√≥ th·ªÉ √°p d·ª•ng.
    # Ch·ªâ tr·∫£ l·ªùi v·ªõi 3 m·ª•c tr√™n, kh√¥ng gi·∫£i th√≠ch th√™m.
    # V√≠ d·ª•:
    # T√¨nh hu·ªëng: "Hai v·ª£ ch·ªìng ƒë·ªìng √Ω ly h√¥n v√† ƒë√£ th·ªèa thu·∫≠n xong vi·ªác chia t√†i s·∫£n."
    # Tr·∫£ l·ªùi:
    # T√≥m t·∫Øt: Thu·∫≠n t√¨nh ly h√¥n, ƒë√£ th·ªèa thu·∫≠n chia t√†i s·∫£n.
    # T·ª´ kh√≥a: Thu·∫≠n t√¨nh ly h√¥n, chia t√†i s·∫£n.
    # ƒêi·ªÅu lu·∫≠t: ƒêi·ªÅu 55. Thu·∫≠n t√¨nh ly h√¥n.

    # ƒê√¢y l√† c√¢u h·ªèi d√†nh cho b·∫°n: {state['question']}
    # """

    session_id = state.get('session_id')
    conversation_context = ""

    if session_id:
        try:
            # L·∫•y 5 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ c√≥ context
            context_messages = chat_history_manager.get_conversation_context(session_id, 5)
            
            if context_messages:
                conversation_context = "\n--- NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN TR∆Ø·ªöC ƒê√ì ---\n"
                for msg in context_messages[:-1]:  # Lo·∫°i b·ªè tin nh·∫Øn hi·ªán t·∫°i
                    role = "üë§ Ng∆∞·ªùi d√πng" if msg['role'] == 'user' else "ü§ñ Tr·ª£ l√Ω"
                    conversation_context += f"{role}: {msg['content'][:200]}{'...' if len(msg['content']) > 200 else ''}\n"
                conversation_context += "--- K·∫æT TH√öC NG·ªÆ C·∫¢NH ---\n\n"
        except Exception as e:
            print(f"L·ªói khi l·∫•y context: {e}")
            conversation_context = ""

    prompt = f"""
    B·∫°n l√† chuy√™n gia Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh Vi·ªát Nam 2014. Khi nh·∫≠n ƒë∆∞·ª£c m·ªôt t√¨nh hu·ªëng ho·∫∑c c√¢u h·ªèi, h√£y:

    Nhi·ªám v·ª• c·ªßa b·∫°n:
    1. **ƒê·ªçc ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán** (n·∫øu c√≥) ƒë·ªÉ hi·ªÉu m·∫°ch c√¢u chuy·ªán v√† c√°c v·∫•n ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c th·∫£o lu·∫≠n.
    2. **Ph√¢n t√≠ch c√¢u h·ªèi hi·ªán t·∫°i** trong b·ªëi c·∫£nh c·ªßa cu·ªôc tr√≤ chuy·ªán.
    3. **T√≥m t·∫Øt n·ªôi dung ch√≠nh** c·ªßa t√¨nh hu·ªëng (bao g·ªìm c·∫£ context tr∆∞·ªõc ƒë√≥ n·∫øu li√™n quan).
    4. **Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng** t·ª´ t√¨nh hu·ªëng v√† 5 t·ª´ kh√≥a t∆∞∆°ng t·ª± c√πng √Ω nghƒ©a.
    5. **Li·ªát k√™ c√°c ƒëi·ªÅu lu·∫≠t** c√≥ th·ªÉ √°p d·ª•ng.

    Ch·ªâ tr·∫£ l·ªùi v·ªõi 3 m·ª•c cu·ªëi (t√≥m t·∫Øt, t·ª´ kh√≥a, ƒëi·ªÅu lu·∫≠t), kh√¥ng gi·∫£i th√≠ch th√™m.

    V√≠ d·ª•:
    T√¨nh hu·ªëng: "Hai v·ª£ ch·ªìng ƒë·ªìng √Ω ly h√¥n v√† ƒë√£ th·ªèa thu·∫≠n xong vi·ªác chia t√†i s·∫£n."
    Tr·∫£ l·ªùi:
    T√≥m t·∫Øt: Thu·∫≠n t√¨nh ly h√¥n, ƒë√£ th·ªèa thu·∫≠n chia t√†i s·∫£n.
    T·ª´ kh√≥a: Thu·∫≠n t√¨nh ly h√¥n, chia t√†i s·∫£n, ly h√¥n, th·ªèa thu·∫≠n, t√†i s·∫£n.
    ƒêi·ªÅu lu·∫≠t: ƒêi·ªÅu 55. Thu·∫≠n t√¨nh ly h√¥n.

    ƒê√¢y l√† ng·ªØ c·∫£nh:
    {conversation_context}
    ƒê√¢y l√† c√¢u h·ªèi d√†nh cho b·∫°n: {state['question']}
    """

    
    response = llm.invoke(prompt)
    
    return {
        "instruction": response.content
    }
def chatbot(state):

    session_id = state.get('session_id')
    conversation_context = ""

    if session_id:
        try:
            # L·∫•y 5 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ c√≥ context
            context_messages = chat_history_manager.get_conversation_context(session_id, 5)
            
            if context_messages:
                conversation_context = "\n--- NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN TR∆Ø·ªöC ƒê√ì ---\n"
                for msg in context_messages[:-1]:  # Lo·∫°i b·ªè tin nh·∫Øn hi·ªán t·∫°i
                    role = "üë§ Ng∆∞·ªùi d√πng" if msg['role'] == 'user' else "ü§ñ Tr·ª£ l√Ω"
                    conversation_context += f"{role}: {msg['content'][:200]}{'...' if len(msg['content']) > 200 else ''}\n"
                conversation_context += "--- K·∫æT TH√öC NG·ªÆ C·∫¢NH ---\n\n"
        except Exception as e:
            print(f"L·ªói khi l·∫•y context: {e}")
            conversation_context = ""

    # Prompt c·∫£i ti·∫øn cho t√°c v·ª• RAG
    prompt = f"""
    B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¥ng minh, chuy√™n s√¢u v·ªÅ Lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh Vi·ªát Nam. 
    B·∫°n c√≥ kh·∫£ nƒÉng truy c·∫≠p v√†o c√°c t√†i li·ªáu ph√°p l√Ω li√™n quan ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß nh·∫•t.

    D∆∞·ªõi ƒë√¢y l√† t√†i li·ªáu ph√°p l√Ω m√† b·∫°n c√≥ th·ªÉ tham kh·∫£o ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. 
    Vui l√≤ng ph√¢n t√≠ch context, c√¢u h·ªèi v√† s·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu ƒë·ªÉ cung c·∫•p c√¢u tr·∫£ l·ªùi r√µ r√†ng v√† ch√≠nh x√°c.

    T√†i li·ªáu ph√°p l√Ω: {state['documents']}

    {conversation_context}

    C√¢u h·ªèi: {state['question']}

    L∆∞u √Ω: ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n c√°c quy ƒë·ªãnh v√† ƒëi·ªÅu kho·∫£n trong c√°c t√†i li·ªáu ph√°p l√Ω, kh√¥ng th√™m th√¥ng tin ngo√†i t√†i li·ªáu.
    """
    
    # G·ª≠i prompt v√† c√¢u h·ªèi v√†o LLM ƒë·ªÉ nh·∫≠n c√¢u tr·∫£ l·ªùi
    response = llm.invoke(prompt)
    
    return {
        "answer": [response]
    }


workflow = StateGraph(GraphState)
# ƒê·ªãnh nghƒ©a c√°c node
workflow.add_node("preprocess_query", preprocess_query)
workflow.add_node("wiki_search", wiki_search)  # web search
workflow.add_node("retrieve", retrieve)  # retrieve
workflow.add_node("chatbot", chatbot)  # chatbot
# preprocess_query

# ƒê·ªãnh nghƒ©a c√°c c·∫°nh
# X√¢y d·ª±ng ƒë·ªì th·ªã
# workflow.add_edge(START, "preprocess_query")
workflow.add_conditional_edges(
    START,
    route_question,
    {
        "wiki_search": "wiki_search",
        "vectorstore": "preprocess_query",
    },
)
workflow.add_edge( "preprocess_query", "retrieve")
workflow.add_edge( "retrieve", "chatbot")
workflow.add_edge( "wiki_search", "chatbot")
workflow.add_edge( "chatbot", END)

# Compile
graph = workflow.compile()

try:
    graph_image = graph.get_graph().draw_mermaid_png()
    with open("workflow_graph.png", "wb") as f:
        f.write(graph_image)
    print("\nƒê√£ l∆∞u ƒë·ªì th·ªã workflow v√†o file 'workflow_graph.png'")
except Exception as e:
    print(f"\nKh√¥ng th·ªÉ t·∫°o ƒë·ªì th·ªã: {str(e)}")


# endpoints
class UserCreate(BaseModel):
    username: str
    email: Optional[str] = None

class SessionCreate(BaseModel):
    user_id: str
    title: Optional[str] = "New Chat"

class QuestionInput(BaseModel):
    user_id: str
    session_id: Optional[str] = None
    question: str

class SessionUpdate(BaseModel):
    title: str

class MessageSearch(BaseModel):
    user_id: str
    query: str

@app.post("/api/users")
async def create_user(user: UserCreate):
    """T·∫°o user m·ªõi"""
    try:
        user_id = chat_history_manager.create_user(user.username, user.email)
        if user_id:
            return {"status": "success", "user_id": user_id}
        else:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ t·∫°o user")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/users/{username}")
async def get_user_by_username(username: str):
    """L·∫•y th√¥ng tin user theo username"""
    try:
        user = chat_history_manager.get_user_by_username(username)
        if user:
            return {"status": "success", "user": user}
        else:
            raise HTTPException(status_code=404, detail="User not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/users/{user_id}/sessions")
async def get_user_sessions(user_id: str, limit: int = 50):
    """L·∫•y danh s√°ch sessions c·ªßa user"""
    try:
        sessions = chat_history_manager.get_user_sessions(user_id, limit)
        return {"status": "success", "sessions": sessions}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.post("/api/sessions")
async def create_session(session: SessionCreate):
    """T·∫°o session m·ªõi"""
    try:
        session_id = chat_history_manager.create_session(session.user_id, session.title)
        if session_id:
            return {"status": "success", "session_id": session_id}
        else:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ t·∫°o session")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/sessions/{session_id}/messages")
async def get_session_messages(session_id: str, limit: int = 100):
    """L·∫•y messages c·ªßa session"""
    try:
        messages = chat_history_manager.get_session_messages(session_id, limit)
        return {"status": "success", "messages": messages}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/sessions/{session_id}")
async def update_session(session_id: str, session_update: SessionUpdate):
    """C·∫≠p nh·∫≠t title session"""
    try:
        success = chat_history_manager.update_session_title(session_id, session_update.title)
        if success:
            return {"status": "success", "message": "Session updated successfully"}
        else:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t session")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """X√≥a session"""
    try:
        success = chat_history_manager.delete_session(session_id)
        if success:
            return {"status": "success", "message": "Session deleted successfully"}
        else:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ x√≥a session")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# Chat Endpoints
@app.post("/api/chat")
async def chat(inputs: QuestionInput):
    """Chat v·ªõi bot v√† l∆∞u l·ªãch s·ª≠"""
    try:
        # N·∫øu kh√¥ng c√≥ session_id, t·∫°o session m·ªõi
        session_id = inputs.session_id
        if not session_id:
            session_id = chat_history_manager.create_session(inputs.user_id, "New Chat")
            if not session_id:
                raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ t·∫°o session")

        # L·∫•y conversation context hi·ªán t·∫°i (ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng trong t∆∞∆°ng lai)
        conversation_context = chat_history_manager.get_conversation_context(session_id, 10)

        # L∆∞u c√¢u h·ªèi c·ªßa user
        user_message_id = chat_history_manager.add_message(
            session_id, "user", inputs.question
        )
        
        # X·ª≠ l√Ω c√¢u h·ªèi v·ªõi graph
        results = graph.invoke({
            "question": inputs.question,
            "session_id": session_id
        })
        #answer = results.get('answer', '')

        raw_answer = results.get('answer', '')
        if isinstance(raw_answer, list) and len(raw_answer) > 0:
            # N·∫øu answer l√† list, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
            answer_obj = raw_answer[0]
            if hasattr(answer_obj, 'content'):
                # N·∫øu l√† AIMessage, l·∫•y content
                answer = answer_obj.content
            else:
                answer = str(answer_obj)
        elif hasattr(raw_answer, 'content'):
            # N·∫øu tr·ª±c ti·∫øp l√† AIMessage
            answer = raw_answer.content
        else:
            # Fallback to string conversion
            answer = str(raw_answer)
        
        print(f"[DEBUG] Raw answer type: {type(raw_answer)}")
        print(f"[DEBUG] Processed answer: {answer[:100]}...")
        
        # L∆∞u c√¢u tr·∫£ l·ªùi c·ªßa assistant
        assistant_message_id = chat_history_manager.add_message(
            session_id, "assistant", answer
        )

        from datetime import datetime

        context_metadata = {
            "last_question": inputs.question,
            "last_answer": answer[:500] + "..." if len(answer) > 500 else answer,
            "conversation_length": len(conversation_context) + 2,
            "timestamp": datetime.now().isoformat(),
            "user_id": inputs.user_id,
            "processing_results": {
                #"route_used": "vectorstore" if "vectorstore" in str(graph) else "wiki_search",
                "has_documents": "documents" in results,
                "result_keys": list(results.keys()) if isinstance(results, dict) else []
            }
        }
        
        context_saved = chat_history_manager.save_session_context(session_id, context_metadata)
        print(f"Context saved: {context_saved}")

        # T·ª± ƒë·ªông c·∫≠p nh·∫≠t title session n·∫øu ƒë√¢y l√† tin nh·∫Øn ƒë·∫ßu ti√™n
        session_messages = chat_history_manager.get_session_messages(session_id, 5)
        if len(session_messages) == 2:  # Ch·ªâ c√≥ 2 tin nh·∫Øn (user + assistant)
            # T·∫°o title ng·∫Øn g·ªçn t·ª´ c√¢u h·ªèi
            title = inputs.question[:50] + "..." if len(inputs.question) > 50 else inputs.question
            chat_history_manager.update_session_title(session_id, title)
        
        return {
            "status": "success",
            "session_id": session_id,
            "answer": answer,
            "user_message_id": user_message_id,
            "assistant_message_id": assistant_message_id,
            "context_saved": context_saved,
            "conversation_context_lenght": len(conversation_context),
        }
    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        print(f"Error type: {type(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/sessions/{session_id}/context")
async def get_conversation_context(session_id: str, last_n_messages: int = 10):
    """L·∫•y context conversation"""
    try:
        context = chat_history_manager.get_conversation_context(session_id, last_n_messages)
        return {"status": "success", "context": context}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.post("/api/sessions/{session_id}/save_context")
async def save_session_context_endpoint(session_id: str, context_data: dict):
    """Test endpoint ƒë·ªÉ l∆∞u context"""
    try:
        success = chat_history_manager.save_session_context(session_id, context_data)
        if success:
            return {"status": "success", "message": "Context saved"}
        else:
            return {"status": "error", "message": "Failed to save context"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.get("/api/sessions/{session_id}/statistics")
async def get_session_statistics(session_id: str):
    """L·∫•y th·ªëng k√™ session"""
    try:
        stats = chat_history_manager.get_session_statistics(session_id)
        return {"status": "success", "statistics": stats}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# Search Endpoints
@app.post("/api/search/messages")
async def search_messages(search: MessageSearch):
    """T√¨m ki·∫øm messages"""
    try:
        messages = chat_history_manager.search_messages(search.user_id, search.query)
        return {"status": "success", "messages": messages}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/chat")
# async def chat(inputs: QuestionInput):
#     # results = []
    
#     # # Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ `app.stream()` cho ph√©p l·∫•y c√°c output t·ª´ c√¢u h·ªèi.
#     # for output in graph.invoke({"question": inputs.question}):
#     #     output_result = {}
#     #     for key, value in output.items():
#     #         output_result[key] = value
#     #     results.append(output_result)
#     results = graph.invoke({"question": inputs.question})
#     answer = results.get('answer','')
#     #save_chat_history(inputs.user_id, inputs.question, answer)
#     return {"results": results}

# PDF Upload Endpoint
@app.post("/api/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    # L∆∞u file t·∫°m th·ªùi
    file_location = f"temp_{file.filename}"
    with open(file_location, "wb") as f:
        f.write(await file.read())
    # 1. Tr√≠ch xu·∫•t text
    raw_text = extract_text_from_pdf(file_location)
    # 2. Kh·ªüi t·∫°o class thao t√°c DB
    db_config = {
        "host": "localhost",
        "user": "root",
        "password": "hoangducdung",
        "database": "law_db"
    }
    doc_creator = LawDocumentCreator(**db_config)
    # 3. L∆∞u v√†o MySQL
    doc_creator.add_chapters_and_articles_to_db(raw_text)
    # 4. T·∫°o Document t·ª´ MySQL
    documents = doc_creator.create_documents_from_db()
    # 5. Upsert v√†o Qdrant
    qdrant_vectors.upsert_documents(documents)
    return {"status": "success", "filename": file.filename}

# Health Check
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "message": "Law Chat API is running"}